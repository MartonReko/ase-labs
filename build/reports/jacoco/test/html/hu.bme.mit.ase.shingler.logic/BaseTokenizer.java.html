<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>BaseTokenizer.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">shingler</a> &gt; <a href="index.source.html" class="el_package">hu.bme.mit.ase.shingler.logic</a> &gt; <span class="el_source">BaseTokenizer.java</span></div><h1>BaseTokenizer.java</h1><pre class="source lang-java linenums">package hu.bme.mit.ase.shingler.logic;

import hu.bme.mit.ase.shingler.lib.Tokenizer;
import hu.bme.mit.ase.shingler.lib.data.TokenVector;
import hu.bme.mit.ase.shingler.lib.data.TokenizedDocument;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.regex.Pattern;

<span class="fc" id="L11">public class BaseTokenizer implements Tokenizer {</span>

<span class="fc" id="L13">    private static final Logger logger = LoggerFactory.getLogger(BaseTokenizer.class);</span>

<span class="fc" id="L15">    private final static Pattern sentencesPattern = Pattern.compile(&quot;[?!.]&quot;);</span>
<span class="fc" id="L16">    private final static Pattern wordsPattern = Pattern.compile(&quot;[^a-z0-9]&quot;);</span>
<span class="fc" id="L17">    private final static Pattern charactersPattern = Pattern.compile(&quot;&quot;);</span>

    @Override
    public TokenizedDocument tokenize(String document, boolean isWordGranularity) {
<span class="fc" id="L21">        logger.info(&quot;Tokenizing document with word granularity = {}&quot;, isWordGranularity);</span>

<span class="fc" id="L23">        var normalizedDocument = document.toLowerCase();</span>

<span class="fc bfc" id="L25" title="All 2 branches covered.">        if (isWordGranularity) {</span>
<span class="fc" id="L26">            return tokenize(normalizedDocument, sentencesPattern, wordsPattern);</span>
        } else {
<span class="fc" id="L28">            return tokenize(normalizedDocument, wordsPattern, charactersPattern);</span>
        }
    }

    private TokenizedDocument tokenize(String document, Pattern sentencePattern, Pattern wordPattern) {
<span class="fc" id="L33">        return new TokenizedDocument(</span>
<span class="fc" id="L34">                sentencePattern.splitAsStream(document)</span>
<span class="pc bpc" id="L35" title="1 of 2 branches missed.">                        .filter(s -&gt; !s.isEmpty())</span>
<span class="fc" id="L36">                        .map(s -&gt;</span>
<span class="fc" id="L37">                                new TokenVector(</span>
<span class="fc" id="L38">                                        wordPattern.splitAsStream(s)</span>
<span class="fc bfc" id="L39" title="All 2 branches covered.">                                                .filter(w -&gt; !w.isEmpty())</span>
<span class="fc" id="L40">                                                .toList()</span>
                                )
                        )
<span class="fc" id="L43">                        .toList()</span>
        );
    }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.12.202403310830</span></div></body></html>